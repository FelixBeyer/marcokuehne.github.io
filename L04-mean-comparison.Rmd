# Mean Comparison

<!-- ::: {.infobox data-latex="warning"} -->
<!-- **Learning Goals** -->

<!-- - Conceptual Skills:  -->
<!--   + How to calculate the mean.  -->
<!--   + Compare means between people or groups. -->
<!--   + Compare means for people or groups over time -->
<!--   + Compare yourself to the rest of the world.  -->
<!--   + What Student’s t-test has to do with beer.  -->
<!-- - Data Concepts: Factor variables. -->
<!-- - R Skills:  -->
<!--     +   Data Manipulation: Several options to achieve a goal.  -->
<!--     +   Data Analysis: Hypothesis testing with t-Tests.  -->
<!--     +   Data Visualization: Error plots.  -->
<!-- ::: -->

<!-- https://methods.sagepub.com/reference/encyc-of-research-design/n237.xml -->

The term mean comparisons refers to the comparison of the average of one or more continuous variables over one or more categorical variables. It is a general term that can refer to a large number of different research questions and study designs. For example, one can compare the mean from one sample of data to a hypothetical population value, compare the means on a single variable from multiple independent groups, or compare the means for a single variable for one sample over multiple measurement occasions. In addition, more complex research designs can employ multiple continuous dependent variables simultaneously, as well as a combination of multiple groups and multiple measurement occasions. Overall, mean comparisons are of central interest in any experimental design and many correlational designs.

:::: {.dedicated}
::: {.titeldedicated}
<h2> Truly Dedicated </h2>
:::
The **mean** usually refers to the **arithmetic mean**. Together with the **geometric** and the **harmonic mean** it satisfies the relationship $\mathrm{AM} \ge \mathrm{GM} \ge \mathrm{HM}$.
::::

The arithmetic mean is calculated as: 

$\bar{x} = \frac{1}{n}\left (\sum_{i=1}^n{x_i}\right ) = \frac{x_1+x_2+\cdots +x_n}{n}$

For example, the arithmetic mean of five values: 4, 36, 45, 50, 75 is:

$\dfrac{4+36+45+50+75}{5} = \dfrac{210}{5} = 42.$

## Application

In this application we compare the health situation between men and women.

### Data Preparation 

Load SOEP practice data from Github repository directly into memory. 

```{r warning=FALSE, message=FALSE}
library(haven)
soep <- read_dta("https://github.com/MarcoKuehne/marcokuehne.github.io/blob/main/data/SOEP/soep_lebensz_en/soep_lebensz_en.dta?raw=true")

# Complete case study
library(tidyverse)
soep <- soep %>% filter(complete.cases(.))

# Subset the year 2000
soep_2000 <- subset(soep, year == 2000)
```

### Grouped Mean

There are several options to calculate means per group. 

```{r message=FALSE, warning=FALSE}
## TAPPLY
means1 <- tapply(soep_2000$health_org, INDEX=soep_2000$sex, FUN=mean)  
means1
``` 

```{r message=FALSE, warning=FALSE}
## AGGREGATE 
means2 <- aggregate(health_org~sex, soep_2000, mean)                
means2
```

```{r message=FALSE, warning=FALSE}
## BY 
means3 <- by(soep_2000$health_org, soep_2000$sex, mean)
means3
```

The `class(means1)` is an `array`, `class(means3)` is `by`. `means2` is a dataframe. None of these base R functions reminds of what the values `0` and `1` stand for. The `tidyverse` package makes use of built in labels.

```{r message=FALSE, warning=FALSE}
## DPLYR pipe 
library(tidyverse)
means4 <- soep_2000 %>% 
  group_by(sex)%>% 
  summarize(means = mean(health_org))
means4
```

<!-- Check how different `means1`, `means2` and `means3` look like in the console.  -->

<!-- Means can be compared in plain text. The mean education of men in 2000 is `r by(soep_2000$education, soep_2000$sex, mean)[1]` years and mean education of women in 2000 is `r by(soep_2000$education, soep_2000$sex, mean)[2]` years. But how to evaluate this difference? Is there a meaningful difference? Is it almost equal? We add confidence intervals to group means as a measure of uncertainty. -->

### Furious with Factors

The `dplyr` solution uses labels (notice the type `<dbl+lbl>` for `sex` and `<dbl>` for `means`). Only few datasets comes with labels. And not all packages can handle them. The old fashioned way in R to have a readable and usable label is to define `sex` as a **factor variable**. 

:::: {.defbox}
::: {.titeldefbox}
<h2> Definition </h2>
:::
A **factor variable** is a variable used for categorical data. 
::::

Categories can be ordered (e.g. small, medium, large) or without order (e.g. men, women). An integer or string can be converted to a factor. Factors have hidden **levels**. Several R functions and packages treat factors fundamentally different from integers. When R handles `sex` as an integer, it assumes that values such as `sex=-3` and `sex=1.5` are possible. 

This is what happens to numbers.

```{r }
gender_numbers <- c(0, 1, 0, 1, 1)
summary(gender_numbers)
```

A mean can be calculated. Compare to character coding. 

```{r }
gender_words <- c("male", "female", "male", "female", "female")
summary(gender_words)
```

Now, convert the gender variable to a factor and calculate the mean again.

```{r }
soep_2000$sex_factor <- as.factor(soep_2000$sex) 
levels(soep_2000$sex_factor) <- c("male", "female") 
means <- tapply(soep_2000$health_org, INDEX=soep_2000$sex_factor, FUN=mean) 
means
```

<!-- First, we analyze the statistical significance of the mean difference. Then, we plot the mean difference.  -->

The average health status is higher for men in comparison to women in the data. What can we learn from this difference? Is it small or large? Is it a cause for concern? How can we become more confident of the result? We do a statistical test that compares the means. 

<!-- The interval of all observed values can be investigated with the `summary(soep_2000$satisf_org)` as min/max.  -->
<!-- https://www.statisticshowto.com/probability-and-statistics/hypothesis-testing/ -->
<!-- A statistical hypothesis test is a method of statistical inference used to decide whether the data at hand sufficiently support a particular hypothesis.  -->

:::: {.defbox}
::: {.titeldefbox}
<h2> Definition </h2>
:::
**Hypothesis testing** in statistics is a way to test the results of a survey or experiment to see if there are meaningful results.
::::

It's basically testing whether the results are valid by figuring out the odds that the results have happened by chance. If the results may have happened by chance, the experiment won’t be repeatable and so has little use. 

### Plot with Confidence 
<!-- http://www.sthda.com/english/wiki/plot-group-means-and-confidence-intervals-r-base-graphs -->

Time to plot. In addition to the group means we plot **confidence intervals** using the `gplots` package with the `plotmeans()` function. The result is this: 

```{r message=FALSE, warning=FALSE, echo = FALSE, eval=TRUE}
library(gplots)
## Plot the mean of teeth length by dose groups
plotmeans(health_org ~ sex_factor, data = soep_2000, frame = FALSE)
```

`plotmeans()` nicely presents the number of observations and labels by default.

:::: {.dedicated}
::: {.titeldedicated}
<h2> Truly Dedicated </h2>
:::
There is a statistically significant difference, **when confidence intervals not overlap**.
::::

Conclusion: Don't worry about the health differential. 

<!-- A t-test is indeed more about a **t-value**. Although, applied researcher and data scientists are more interested in the **p-value**.  -->

<!-- The formula on Wikipedia [Dependent t-test for paired samples](https://en.wikipedia.org/wiki/Student%27s_t-test##Dependent_t-test_for_paired_samples) comes as follows: -->

<!-- $$ t = \frac{\bar{X}_D - \mu_0}{s_D/\sqrt n} $$ -->

## Student's t-test
<!-- https://statsandr.com/blog/student-s-t-test-in-r-and-by-hand-how-to-compare-two-groups-under-different-scenarios/##how-to-compute-students-t-test-by-hand -->
<!-- https://suinotes.wordpress.com/2009/11/30/understanding-t-test-in-r/ -->

<details>
<summary>
*What this has do to with beer.*
</summary>
:::: {.dedicated}
::: {.titeldedicated}
<h2> Truly Dedicated </h2>
:::
**Student's t-test** or simply t-test was published by W.S. Gossett who hid his name due to his position as a worker in a **brewery company** (Guiness Brewery Dublin). 
::::

</details>


<!-- Now we learn about two different versions of the two sample t-test that either work for one measurement (one point in time) or two measurements (before-after setting). -->
There are several versions of a [Student's t-test](https://en.wikipedia.org/wiki/Student%27s_t-test). The first distinction is whether there are one or two samples (groups). If there are two groups, the second distinction is whether there are one or two measurements in time.^[There was a specific reason why we filtered for a particular year at the beginning.]

* One sample t-test
* Two sample tests
  + Independent (or unpaired) t-test
    - Classical Two Sample t-test (equal variances, i.e. *homoscedasticity*)
    - Welch Two Sample t-test (unequal variances)
  + Dependent (or paired or repeated) t-test

Which is the most common one? Ask the simple implementation `t.test()` that tells you that it's a **Welch Two Sample t-test**.^[Unfortunately, Bernard Lewis Welch did not work for a Brewery company.] The Welch's t-test (or unequal variances t-test), is a two-sample location test which is used to test the hypothesis that two populations have equal means when the assumption of equal variances is dropped. The `t.test()` is unpaired since the **default** option is `paired=FALSE`. We will use the unpaired t-test for mean comparison between genders, since men and women are *independent* in the sense of statistical samples (though they may be related in other circumstances). 

### Independent t-test 

The `t.test()` in R takes a `formula` and `data` as input. The relationship between `health_org` and `sex_factor` is specified as `health_org ~ sex_factor`, i.e. explain or calculate the `health_org` by `sex_factor` (if other way around, R returns an error message).  

```{r echo = TRUE, eval=TRUE}
t.test(health_org ~ sex_factor, data=soep_2000)
```

```{r echo = F}
t <- t.test(health_org ~ sex, data=soep_2000)
```

Look at the output of the t-test:

-   The so called t-statistic is `r t$statistic`
-   The degrees of freedom are `r t$parameter`
-   The p-value of `r t$p.value`
-   The 95% confidence interval is [`r t$conf.int[1]`;`r t$conf.int[2]`]

The t-statistic is at the heart of this hypothesis test. The t value has to be compared to a critical value in a t table to decide whether or not to reject the **null hypothesis** (H0). The null states: Move along, there's nothing to see here!

The p-value can be seen as easy-alternative to the t-statistic. You probably never look up critical t values, do you? If you just want to glimpse at it, [here is one]( https://jimgrange.wordpress.com/2015/12/05/statistics-tables-where-do-the-numbers-come-from/). We are looking forward getting **small p-values** (smaller than 0.05 by convention). If p < 0.05 we say that we reject the null and conclude that there is actually something going on! 

:::: {.defbox}
::: {.titeldefbox}
<h2> Definition </h2>
:::
If a p value is less than 0.05, the result is called **statistically significant**.
::::

The 95% confidence interval (CI) is another way of looking at the same issue. 95% of the values should be in the interval 0.1 to 0.3. Thus if zero is not in the CI we can be pretty sure that something is going on.

Degrees of freedom prefer to keep an air of mystery about them.

<!-- When building models, you want to have more observations than parameters that are estimated for the model. These extra variables are called degrees of freedom.  -->

### Dependent t-test 
<!-- http://www.sthda.com/english/wiki/paired-samples-t-test-in-r -->

We prepare a before-after sample and focus on all women who are observed in 2000 and 2004. 

```{r echo = TRUE, eval=TRUE}
women_before_after <- soep %>%
  filter(sex == 1) %>% ## filter all females
  filter(year == 2000 | year == 2004) %>% ## only use year 2000 OR 2004
  group_by(id) %>% ## look at id groups
  filter(n() == 2) ## only keep groups with exactly two observations/rows
```

Now run the t.test as `paired=TRUE`. 

```{r echo = TRUE, eval=TRUE}
t.test(health_org ~ year, data=women_before_after, paired=TRUE)
```

It looks like women have been significantly more healthy in 2000 than in 2004. Can you think of a reason? What happened to all those women? 

:::: {.challenge}
::: {.titelchallenge}
<h2> Your Turn </h2>
:::
Can you name a reason for the significant difference in health? 
::::

The paired t-test is a little bit more demanding in the way that we need data on something observed at two different points in time. In this before-and-after scenario, the person serves as something like its own control group. We'll come back to that. 

What happens if we have paired data, but apply the unpaired test? The unpaired t-test on women's health is:

```{r echo = TRUE, eval=TRUE}
t.test(health_org ~ year, data=women_before_after, paired=FALSE)
```

The mean difference is exactly the same. Can you spot it? Ask your console to calculate the difference between 3.497549 and 3.325980). But all the other statistics seem to be different: t-value, degree of freedom, p-value ... 

:::: {.amazing}
::: {.titelamazing}
<h2> Amazing Fact </h2>
:::
In this scenario the mean difference from the `paired=TRUE` and `paired=FALSE` test are identical. But using the information from the **paired sample** (one person observed for two periods), the **t-value became higher and thus the p-value lower**. In a nutshell, we gained more statistical confidence in our estimate!
::::

Once more we saw how valuable time is. We explore this in more detail in the next chapter. 

<!-- https://scandiweb.com/blog/t-tests-explained/ -->
<!-- The way it works is as follows. During any type of t-test, your sample data (size and variability) is processed and distilled to a single number – the t-value. The result equal to zero means that your data matches the null hypothesis and there are no irregularities found. The increase in the absolute value of the t-value signifies that the difference between the sample data and the null hypothesis is also increasing. -->

<!-- Please hard code this formula by hand in R. In detail: -->

<!-- - Calculate the differences (before/old and after/new) in the paired sample. -->
<!-- - Calculate the mean of these differences.  -->
<!-- - Calculate the number of pairs. -->
<!-- - Calculate the standard deviation of the differences.  -->
<!-- - Please store all those values in R objects, i.e. never assign a number such as `n <- 100`.  -->
<!-- - Put everything together according to the formula above.  -->

<!-- https://statsandr.com/blog/student-s-t-test-in-r-and-by-hand-how-to-compare-two-groups-under-different-scenarios/ -->

```{r echo = FALSE, eval=TRUE}
paired_ttest <- women_before_after %>%
  group_by(id) %>%
  mutate(satis_lag = lag(satisf_org),
         satis_diff = satisf_org - lag(satisf_org)) %>% ## after (new) - before (old)
  select(id, year, satisf_org, satis_lag, satis_diff) 

## mean difference
pairs_diff <- mean(paired_ttest$satis_diff, na.rm = TRUE)

## number of pairs is number of people, not obs! 
pairs_n <- nrow(women_before_after)/2

## standard deviation of the difference in the population
pairs_sd <- sd(paired_ttest$satis_diff, na.rm=TRUE)

pairs_t <- pairs_diff/(pairs_sd/sqrt(pairs_n))
```



### One sample t-test

There is a one sample t-test which does not help much for group comparison.


<details>
<summary>
*Now, you can call yourself ...*
</summary>
![](images/mr-t-test.jpg)
</details>


<!-- ![half-size image](foo.jpg){##id .class width=50% height=50%} -->
